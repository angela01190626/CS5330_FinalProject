{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1fd4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Image Library is a very useful library for processing images\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import layers\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import os\n",
    "import fnmatch\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "668696e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"Demo_dataset\"\n",
    "train_chinese = os.listdir(train_path)\n",
    "df_train = pd.DataFrame(columns=[\"character\", \"filename\", \"label\"])\n",
    "len(train_chinese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5fd234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for i in range(0, len(train_chinese)):\n",
    "    if i != \".DS_Store\":\n",
    "        l = os.listdir(train_path + '/' + train_chinese[i])\n",
    "        l = fnmatch.filter(l, '*.png')\n",
    "        if len(l) > 200:\n",
    "            l = l[:200]\n",
    "        label = [k] * len(l)\n",
    "        temp = pd.DataFrame({\n",
    "            \"character\": train_chinese[i],\n",
    "            \"filename\": l,\n",
    "            \"label\": label\n",
    "        })\n",
    "        #print(temp)\n",
    "        df_train = pd.concat([df_train, temp])      \n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f9e0851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>理</td>\n",
       "      <td>176.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>理</td>\n",
       "      <td>88.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>理</td>\n",
       "      <td>162.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>理</td>\n",
       "      <td>189.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>理</td>\n",
       "      <td>77.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>鸫</td>\n",
       "      <td>93.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>鸫</td>\n",
       "      <td>78.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>鸫</td>\n",
       "      <td>186.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>鸫</td>\n",
       "      <td>192.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>鸫</td>\n",
       "      <td>44.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    character filename label\n",
       "0           理  176.png     0\n",
       "1           理   88.png     0\n",
       "2           理  162.png     0\n",
       "3           理  189.png     0\n",
       "4           理   77.png     0\n",
       "..        ...      ...   ...\n",
       "195         鸫   93.png     7\n",
       "196         鸫   78.png     7\n",
       "197         鸫  186.png     7\n",
       "198         鸫  192.png     7\n",
       "199         鸫   44.png     7\n",
       "\n",
       "[1600 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3fa4da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = np.zeros((df_train.shape[0], 128, 128, 3))\n",
    "for i in range(df_train.shape[0]):\n",
    "    if df_train.iloc[i]['filename'] != \".DS_Store\":\n",
    "        image_path = train_path + '/' + df_train.iloc[i]['character'] + '/' + df_train.iloc[i]['filename']\n",
    "        # get grayscale image\n",
    "        # print(image_path)\n",
    "        image = cv2.imread(image_path)\n",
    "        # remove noise\n",
    "        out = cv2.medianBlur(image, 5)\n",
    "        # normalize the image\n",
    "        resultimage = np.zeros(out.shape)\n",
    "        normalizedimage = cv2.normalize(out, resultimage, 0, 255, cv2.NORM_MINMAX)\n",
    "        # resize the image \n",
    "        resizeimage = cv2.resize(normalizedimage, (128,128))\n",
    "\n",
    "        blue, green, red = cv2.split(resizeimage) \n",
    "        # apply principal component analysis\n",
    "        pca = PCA(50)\n",
    "        red_transformed = pca.fit_transform(red)\n",
    "        red_inverted = pca.inverse_transform(red_transformed)\n",
    "\n",
    "        #Applying to Green channel and then applying inverse transform to transformed array.\n",
    "        green_transformed = pca.fit_transform(green)\n",
    "        green_inverted = pca.inverse_transform(green_transformed)\n",
    "\n",
    "        #Applying to Blue channel and then applying inverse transform to transformed array.\n",
    "        blue_transformed = pca.fit_transform(blue)\n",
    "        blue_inverted = pca.inverse_transform(blue_transformed)\n",
    "\n",
    "        img_compressed = (np.dstack((red_inverted, red_inverted, red_inverted))).astype(np.uint8)\n",
    "        train_array[i] = img_compressed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22b76172",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = train_array / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f33d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89f14eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b2b9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.transpose(train_array, (0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14a3865d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 3, 128, 128)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a028e252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf37e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(128,128,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3)),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(8,activation='softmax')\n",
    "    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49126118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 64)        23296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 15, 15, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 15, 15, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 5, 5, 128)         16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 5, 5, 128)         16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 1,994,248\n",
      "Trainable params: 1,993,096\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=['accuracy']    \n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ad793ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_array,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ef5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "38/38 [==============================] - 6s 157ms/step - loss: 2.7478 - accuracy: 0.1725 - val_loss: 2.0821 - val_accuracy: 0.1325\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 6s 153ms/step - loss: 2.3229 - accuracy: 0.2125 - val_loss: 2.0851 - val_accuracy: 0.1325\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 6s 155ms/step - loss: 2.1182 - accuracy: 0.2892 - val_loss: 2.0965 - val_accuracy: 0.1325\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 6s 161ms/step - loss: 1.9296 - accuracy: 0.3067 - val_loss: 2.1183 - val_accuracy: 0.1325\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 6s 171ms/step - loss: 1.6677 - accuracy: 0.4092 - val_loss: 2.1208 - val_accuracy: 0.1375\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 8s 210ms/step - loss: 1.5455 - accuracy: 0.4483 - val_loss: 2.0735 - val_accuracy: 0.1425\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 7s 182ms/step - loss: 1.4624 - accuracy: 0.4833 - val_loss: 1.9826 - val_accuracy: 0.2025\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 7s 183ms/step - loss: 1.3850 - accuracy: 0.4975 - val_loss: 1.8508 - val_accuracy: 0.2825\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 7s 183ms/step - loss: 1.1992 - accuracy: 0.5692 - val_loss: 1.5484 - val_accuracy: 0.4925\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 7s 182ms/step - loss: 1.1668 - accuracy: 0.5875 - val_loss: 1.2336 - val_accuracy: 0.6650\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 7s 180ms/step - loss: 1.0118 - accuracy: 0.6683 - val_loss: 1.0507 - val_accuracy: 0.7525\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 7s 180ms/step - loss: 0.9634 - accuracy: 0.6717 - val_loss: 0.9514 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 7s 176ms/step - loss: 0.9358 - accuracy: 0.6767 - val_loss: 0.8651 - val_accuracy: 0.7625\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 7s 176ms/step - loss: 0.9231 - accuracy: 0.6750 - val_loss: 0.7560 - val_accuracy: 0.8075\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 7s 176ms/step - loss: 0.7978 - accuracy: 0.7325 - val_loss: 0.7217 - val_accuracy: 0.8275\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 7s 177ms/step - loss: 0.7427 - accuracy: 0.7617 - val_loss: 0.6497 - val_accuracy: 0.8425\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 7s 176ms/step - loss: 0.6684 - accuracy: 0.7733 - val_loss: 0.6365 - val_accuracy: 0.8250\n",
      "Epoch 18/20\n",
      "13/38 [=========>....................] - ETA: 4s - loss: 0.6854 - accuracy: 0.7740"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 20,\n",
    "    validation_data = (X_test, y_test),\n",
    "    validation_freq = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "plt.plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
    "plt.xlabel(\"Epoches\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.figure(figsize = (10, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9694f791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266666769981384"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33356632",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
